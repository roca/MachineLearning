{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2791b581",
   "metadata": {},
   "source": [
    "# DNA Sequence Classification\n",
    "\n",
    "DNA sequences can be classified in different ways. This demo shows how to build a system with Milvus 2.0 and postgres to determine gene families for DNA sequences and compare similarity between different organisms. It uses k-mer and CountVectorizer to extract features and get embeddings for dna sequences.\n",
    "\n",
    "## Data\n",
    "\n",
    "Sample data is downloaded from [Kaggle](https://www.kaggle.com/nageshsingh/dna-sequence-dataset?select=human.txt). This demo uses 6882 DNA sequences for 3 organisms: human (4380), chimpanzee (1682), dog (820), each of which has lines of DNA sequences with corresponding classes in a text file.\n",
    "\n",
    "     - data:\n",
    "        - human_data.txt\n",
    "        - chimp_data.txt\n",
    "        - dog_data.txt\n",
    "\n",
    "Each text file consists of a head line and lines of sequence (a sequence consisting of bases [A, C, G, T]) with its class (an integer from 0 to 6). Sample:\n",
    "                       \n",
    "     sequence class\n",
    "     GCTGCTGCCCCAGCACCAGGTGTCCGCGTACTGA\t6\n",
    "     CACCGGCCCTCCAGGGTCCAGCTGGTGCCCCAGGACACCATGACCAGCAGGGCCTAA\t0\n",
    "\n",
    "Our DNA sequences are classified into different gene families by class. A gene family is a group of related genes sharing a common ancestor. Members of one gene family may be paralogs or orthologs: gene with similar sequences from same or different species. See explanations for 7 classes in our dataset: [Kaggle](https://www.kaggle.com/nageshsingh/demystify-dna-sequencing-with-machine-learning)\n",
    "\n",
    "| Gene family | Class label |\n",
    "|:---|---|\n",
    "| G protein coupled receptors | 0 |\n",
    "| Tyrosine kinase | 1 |\n",
    "| Tyrosine phosphatase | 2 |\n",
    "| Synthetase | 3 |\n",
    "| Synthase | 4 |\n",
    "| Ion channel | 5 |\n",
    "| Transcription | 6 |\n",
    "\n",
    "\n",
    "Run following commands to get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4e229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dna_sequence_classification/data.zip\n",
      "   creating: data/\n",
      "  inflating: data/dog_data.txt       \n",
      "  inflating: data/human_data.txt     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  inflating: data/chimp_data.txt     \n",
      "  inflating: data/gene_class.txt     \n"
     ]
    }
   ],
   "source": [
    "! unzip dna_sequence_classification/data.zip #&& dna_sequence_classification/data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd878c",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We will run codes with python3 and start [Milvus2.0 (Standalone)](https://milvus.io/docs/v2.0.0/install_standalone-docker.md) & postgres with [docker](https://docs.docker.com/get-docker/). Required python modules are listed in `requirements.txt` to install.\n",
    "\n",
    "|    Packages    |     Servers    |\n",
    "| --------------- | -------------- |\n",
    "| pymilvus==2.0.0rc8 | milvus-2.0.0-rc8|\n",
    "|    sklearn    |    mysql    |\n",
    "|   pymysql   |\n",
    "|     numpy   |\n",
    "| pickle-mixin |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134592f",
   "metadata": {},
   "source": [
    "## Up and Running\n",
    "\n",
    "### Install Packages\n",
    "\n",
    "\n",
    "Install the required python packages with requirements.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab3ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymilvus (from -r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for pymilvus from https://files.pythonhosted.org/packages/eb/e9/1092a15322a45d6ca9a403dcf3842272098d76d26041ce6e239a9db40f9f/pymilvus-2.3.6-py3-none-any.whl.metadata\n",
      "  Downloading pymilvus-2.3.6-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting scikit-learn (from -r dna_sequence_classification/requirements.txt (line 3))\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/5b/be/208f17ce87a5e55094b0e8ffd55b06919ab9b56e7e4ce2a64cd9095ec5d2/scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pymysql (from -r dna_sequence_classification/requirements.txt (line 4))\n",
      "  Obtaining dependency information for pymysql from https://files.pythonhosted.org/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r dna_sequence_classification/requirements.txt (line 5)) (1.26.0)\n",
      "Collecting pickle-mixin (from -r dna_sequence_classification/requirements.txt (line 6))\n",
      "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastapi (from -r dna_sequence_classification/requirements.txt (line 7))\n",
      "  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/bf/97/60351307ab4502908d29f64f2801a36709a3f1888447bb328bc373d6ca0e/fastapi-0.109.2-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.109.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn (from -r dna_sequence_classification/requirements.txt (line 8))\n",
      "  Obtaining dependency information for uvicorn from https://files.pythonhosted.org/packages/c7/f3/29caa83f5795b20ed3aca357c648f3ae995ff6ff08e38b22387017abbdc5/uvicorn-0.27.0.post1-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting Python-multipart (from -r dna_sequence_classification/requirements.txt (line 9))\n",
      "  Obtaining dependency information for Python-multipart from https://files.pythonhosted.org/packages/94/35/142fff3d85da49377ada6936ad9b776263549ab22656969b2fcd0bdb10f7/python_multipart-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading python_multipart-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=67 in /usr/local/lib/python3.11/dist-packages (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: grpcio<=1.60.0,>=1.49.1 in /usr/local/lib/python3.11/dist-packages (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (1.58.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (4.24.3)\n",
      "Collecting environs<=9.5.0 (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting ujson>=2.0.0 (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for ujson>=2.0.0 from https://files.pythonhosted.org/packages/d3/93/de6fff3ae06351f3b1c372f675fe69bc180f93d237c9e496c05802173dd6/ujson-5.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ujson-5.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting pandas>=1.2.4 (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for pandas>=1.2.4 from https://files.pythonhosted.org/packages/5b/7e/9fd11ba8e86a8add8f2ff4e11c7111f65ec6fd1b547222160bb969e2bf5e/pandas-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (2.31.0)\n",
      "Collecting minio>=7.0.0 (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for minio>=7.0.0 from https://files.pythonhosted.org/packages/8a/78/4b0fb944cb3f71e6637d8e716593683ea1b41ca5c75ed6a98699d7e31381/minio-7.2.3-py3-none-any.whl.metadata\n",
      "  Downloading minio-7.2.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pyarrow>=12.0.0 (from pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for pyarrow>=12.0.0 from https://files.pythonhosted.org/packages/85/55/636f006d963ddf77270fd294163e149b0719aaaf794de0d023aee88f6335/pyarrow-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pyarrow-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r dna_sequence_classification/requirements.txt (line 3))\n",
      "  Obtaining dependency information for scipy>=1.6.0 from https://files.pythonhosted.org/packages/d4/b8/7169935f9a2ea9e274ad8c21d6133d492079e6ebc3fc69a915c2375616b0/scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->-r dna_sequence_classification/requirements.txt (line 3))\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r dna_sequence_classification/requirements.txt (line 3))\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi->-r dna_sequence_classification/requirements.txt (line 7))\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/db/dc/afecbd9650f486889181c6d1a0d675b580c06253ea7e304588e4c7485bdb/pydantic-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->-r dna_sequence_classification/requirements.txt (line 7))\n",
      "  Obtaining dependency information for starlette<0.37.0,>=0.36.3 from https://files.pythonhosted.org/packages/eb/f7/372e3953b6e6fbfe0b70a1bb52612eae16e943f4288516480860fcd4ac41/starlette-0.36.3-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->-r dna_sequence_classification/requirements.txt (line 7)) (4.8.0)\n",
      "Collecting click>=7.0 (from uvicorn->-r dna_sequence_classification/requirements.txt (line 8))\n",
      "  Obtaining dependency information for click>=7.0 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting h11>=0.8 (from uvicorn->-r dna_sequence_classification/requirements.txt (line 8))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow>=3.0.0 (from environs<=9.5.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for marshmallow>=3.0.0 from https://files.pythonhosted.org/packages/57/e9/4368d49d3b462da16a3bac976487764a84dd85cef97232c7bd61f5bdedf3/marshmallow-3.20.2-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting python-dotenv (from environs<=9.5.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for python-dotenv from https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (2.0.5)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (23.1.0)\n",
      "Collecting pycryptodome (from minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for pycryptodome from https://files.pythonhosted.org/packages/af/20/5f29ec45462360e7f61e8688af9fe4a0afae057edfabdada662e11bf97e7/pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2.4->pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2.4->pymilvus->-r dna_sequence_classification/requirements.txt (line 2))\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/a3/fb/52b62131e21b24ee297e4e95ed41eba29647dad0e0051a92bb66b43c70ff/tzdata-2023.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r dna_sequence_classification/requirements.txt (line 7))\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r dna_sequence_classification/requirements.txt (line 7))\n",
      "  Obtaining dependency information for pydantic-core==2.16.2 from https://files.pythonhosted.org/packages/ad/03/1cac52dfe893109a1571956755061df771457f33cb55264baed8f89635d6/pydantic_core-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi->-r dna_sequence_classification/requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi->-r dna_sequence_classification/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus->-r dna_sequence_classification/requirements.txt (line 2)) (2.21)\n",
      "Downloading pymilvus-2.3.6-py3-none-any.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.7-py3-none-any.whl (22 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading minio-7.2.3-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading ujson-5.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: pickle-mixin\n",
      "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=5991 sha256=4bcb2cb555e38ea2281f4bae6bfb87915fe6122d0302e86bb22dea55e5f02bab\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/9c/0d/8709be17c02b72bf04ea60d8ec64fc46a1554c0fb81e048dd6\n",
      "Successfully built pickle-mixin\n",
      "Installing collected packages: pytz, pickle-mixin, ujson, tzdata, threadpoolctl, scipy, Python-multipart, python-dotenv, pymysql, pydantic-core, pycryptodome, pyarrow, marshmallow, joblib, h11, click, annotated-types, uvicorn, starlette, scikit-learn, pydantic, pandas, environs, fastapi, minio, pymilvus\n",
      "Successfully installed Python-multipart-0.0.7 annotated-types-0.6.0 click-8.1.7 environs-9.5.0 fastapi-0.109.2 h11-0.14.0 joblib-1.3.2 marshmallow-3.20.2 minio-7.2.3 pandas-2.2.0 pickle-mixin-1.0.2 pyarrow-15.0.0 pycryptodome-3.20.0 pydantic-2.6.1 pydantic-core-2.16.2 pymilvus-2.3.6 pymysql-1.1.0 python-dotenv-1.0.1 pytz-2024.1 scikit-learn-1.4.0 scipy-1.12.0 starlette-0.36.3 threadpoolctl-3.2.0 tzdata-2023.4 ujson-5.9.0 uvicorn-0.27.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --trusted-host pypi.python.org --trusted-host pypi.org --trusted-host files.pythonhosted.org -r dna_sequence_classification/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c5cda",
   "metadata": {},
   "source": [
    "### Start Milvus\n",
    "\n",
    "Download and save docker-compose.standalone.yml as docker-compose.yml. Start Milvus2.0 with docker-compose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf19cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-standalone-docker-compose.yml -O docker-compose.yml\n",
    "# ! docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11edf9",
   "metadata": {},
   "source": [
    "### Start Mysql\n",
    "\n",
    "Milvus2.0 does not suppport string for now. Start mysql as docker container to store and recall non-vector attributes of DNA sequences (eg. id, label/class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9b030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d --name mysql mysql:5.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128fbfb",
   "metadata": {},
   "source": [
    "### Check Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61716943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40f465",
   "metadata": {},
   "source": [
    "## Code Overview\n",
    "\n",
    "### Connect to Servers\n",
    "\n",
    "Connect to servers with hosts & ports. In this case, the docker containers are running on localhost and the default ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050822e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, db\n",
    "import pymysql\n",
    "\n",
    "conn = connections.connect(host=\"standalone\", port=19530, db_name=\"bioregistry\")\n",
    "conn = pymysql.connect(host='mariadb', user='mariadb', port=3306, password='password', database='celeritas',local_infile=True)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d718d3",
   "metadata": {},
   "source": [
    "### Create Collection, Partitions, Index in Milvus\n",
    "\n",
    "#### 1. Create Collection\n",
    "\n",
    "Set collection name and dimension value. Create a collection with fields.\n",
    "- Collection name: dna_seq\n",
    "- Dimension: 768\n",
    "- Fields: pk (primary keys), embedding (dna sequence embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dac31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection is successfully created: dna_seq\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pymilvus import utility, Collection, FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "time.sleep(.1)\n",
    "\n",
    "collection_name = \"dna_seq\"\n",
    "dim = 768\n",
    "\n",
    "# Drop the previously stored collection for a clear run\n",
    "if utility.has_collection(collection_name) == True:\n",
    "    collection = Collection(collection_name)\n",
    "    collection.drop()\n",
    "\n",
    "# Set fields & schema\n",
    "all_fields = [\n",
    "        FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dim)\n",
    "        #schema.FieldSchema(name=\"class\", dtype=DataType.STRING)\n",
    "        ]\n",
    "default_schema = CollectionSchema(fields=all_fields, \n",
    "                                  description=\"DNA recognition: kmers & vectorizer\", \n",
    "                                  auto_id=False)\n",
    "\n",
    "# Create collection\n",
    "DNA_collection = Collection(name=collection_name, data=None, schema=default_schema)\n",
    "\n",
    "# Check if collection is successfully created\n",
    "if utility.has_collection(collection_name):\n",
    "    print(\n",
    "    \"Collection is successfully created: \" + collection_name)\n",
    "else:\n",
    "    raise Exception(\"Fail to create collection: \" + collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9b187",
   "metadata": {},
   "source": [
    "#### 2. Create Partitions\n",
    "\n",
    "Create 3 partitions with proper names: human, chimp, dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71e4e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"name\":\"_default\",\"collection_name\":\"dna_seq\",\"description\":\"\"},\n",
       " {\"name\":\"human\",\"collection_name\":\"dna_seq\",\"description\":\"\"},\n",
       " {\"name\":\"chimp\",\"collection_name\":\"dna_seq\",\"description\":\"\"},\n",
       " {\"name\":\"dog\",\"collection_name\":\"dna_seq\",\"description\":\"\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_partition = DNA_collection.create_partition('human')\n",
    "chimp_partition = DNA_collection.create_partition('chimp')\n",
    "dog_partition = DNA_collection.create_partition('dog')\n",
    "\n",
    "DNA_collection.partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678dddc",
   "metadata": {},
   "source": [
    "#### 3. Set Index\n",
    "\n",
    "Set index parameters after collection is created. Here index type is IVF_SQ8 and metric type is Inner Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0280182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is successfully set for collection dna_seq\n"
     ]
    }
   ],
   "source": [
    "index_params = {\n",
    "    'index_type': 'IVF_SQ8',\n",
    "    'params': {'nlist': 512},\n",
    "    'metric_type': 'IP'\n",
    "    }\n",
    "\n",
    "DNA_collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "\n",
    "# Check if index is successfully set\n",
    "if DNA_collection.has_index():\n",
    "    print(\"Index is successfully set for collection \" + collection_name)\n",
    "else:\n",
    "    raise Exception(\"Fail to set index for collection \" + collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fed43",
   "metadata": {},
   "source": [
    "### Create Table in Mysql\n",
    "\n",
    "Create a table with collection name in mySQL to store milvus ids (i.e. field \"pk\") and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dbc3a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create MySQL table successfully!\n"
     ]
    }
   ],
   "source": [
    "# Delete previously stored table for a clean run\n",
    "drop_table = \"DROP TABLE IF EXISTS \" + collection_name + \";\"\n",
    "cursor.execute(drop_table)\n",
    "\n",
    "try:\n",
    "    sql = \"CREATE TABLE if not exists \" + collection_name + \" (pk TEXT, label TEXT);\"\n",
    "    cursor.execute(sql)\n",
    "    print(\"create MySQL table successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"can't create a MySQL table: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b04c32",
   "metadata": {},
   "source": [
    "### Process & Store Datasets\n",
    "\n",
    "#### 1. Get Data\n",
    "\n",
    "Read data from text files as dataframes. Rebuild data and replace original columns with:\n",
    "- sequence --> subsequences by [k-mer](https://en.wikipedia.org/wiki/K-mer#:~:text=Usually%2C%20the%20term%20k%2Dmer,total%20possible%20k%2Dmers%2C%20where) (k=5)\n",
    "- class --> label declaring organism & class (e.g. human: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be95f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence     label  \\\n",
      "0  ATGGAAAATGGCTGCCTGCTTAACTATCTCAGGGAGAATAAAGGAA...  human: 1   \n",
      "1  ATGCGTGGCTTCAACCTGCTCCTCTTCTGGGGATGTTGTGTTATGC...  human: 0   \n",
      "2  NGGCTCTGGGGGCTCCTTCCCCCTGGGCCACCAGCCCTGGCTTGGA...  human: 1   \n",
      "3  ATGGCCCGAAGACCCCGGCACAGCATATATAGCAGTGACGAGGATG...  human: 6   \n",
      "4  TGCTGTGGTGCCATCCTGTTCCCCGTAGTCTGGTCCATCCGGCATC...  human: 0   \n",
      "\n",
      "                                               kmers  \n",
      "0  [ATGG, TGGA, GGAA, GAAA, AAAA, AAAT, AATG, ATG...  \n",
      "1  [ATGC, TGCG, GCGT, CGTG, GTGG, TGGC, GGCT, GCT...  \n",
      "2  [NGGC, GGCT, GCTC, CTCT, TCTG, CTGG, TGGG, GGG...  \n",
      "3  [ATGG, TGGC, GGCC, GCCC, CCCG, CCGA, CGAA, GAA...  \n",
      "4  [TGCT, GCTG, CTGT, TGTG, GTGG, TGGT, GGTG, GTG...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get k-mers for sequence s\n",
    "def build_kmers(s, k):\n",
    "    kmers = []\n",
    "    n = len(s) - k + 1\n",
    "\n",
    "    for i in range(n):\n",
    "        kmer = s[i : i+k].upper()\n",
    "        kmers.append(kmer)\n",
    "\n",
    "    return kmers\n",
    "\n",
    "# Function to replace sequence column with kmers in df\n",
    "def seq_to_kmers(df):\n",
    "    df['kmers'] = df.apply(lambda x: build_kmers(x['sequence'], 4), axis =1)\n",
    "    df = df.drop(['sequence'],axis=1)\n",
    "\n",
    "\n",
    "# Read files\n",
    "human = pd.read_table('./data/human_data.txt')\n",
    "human = human.sample(frac=1, random_state=2021).reset_index(drop=True)\n",
    "chimp = pd.read_table('./data/chimp_data.txt')\n",
    "dog = pd.read_table('./data/dog_data.txt')\n",
    "\n",
    "# Replace classes with labels (organism: class)\n",
    "human['label']=['human: ' + str(x) for x in human['class']]\n",
    "human = human.drop(['class'], axis=1)\n",
    "chimp['label']=['chimp: ' + str(x) for x in chimp['class']]\n",
    "chimp = chimp.drop(['class'], axis=1)\n",
    "dog['label']=['dog: ' + str(x) for x in dog['class']]\n",
    "dog = dog.drop(['class'], axis=1)\n",
    "\n",
    "seq_to_kmers(human)\n",
    "seq_to_kmers(chimp)\n",
    "seq_to_kmers(dog)\n",
    "\n",
    "# Combine all dataframes\n",
    "#df = human.append(chimp).append(dog)\n",
    "#df = df.sample(frac=1,random_state=1)\n",
    "#seq_to_kmers(df)\n",
    "\n",
    "print(human.head())\n",
    "#print(chimp.head())\n",
    "#print(dog.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ecdfa4",
   "metadata": {},
   "source": [
    "Get lists of texts for DNA sequences in k-mers & labels. Split 20 human data to test search performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f3aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train row count: 6101\n",
      "human(3609) chimp(1675) dog(817)\n",
      "test row count: 20\n"
     ]
    }
   ],
   "source": [
    "# Get lists of sequences in k-mers and labels in text from dataframe\n",
    "def mydata(df):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    words = list(df['kmers']) # list of all sequences in kmers\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        texts.append(' '.join(words[i])) \n",
    "    \n",
    "    for x in df['label']:\n",
    "        labels.append(x)\n",
    "\n",
    "    if len(texts)!=len(labels):\n",
    "        raise Exception(\"Texts & labels length are not equal!\")\n",
    "        \n",
    "    return (texts, labels)\n",
    "    \n",
    "human_texts, human_labels = mydata(human)\n",
    "chimp_texts, chimp_labels = mydata(chimp)\n",
    "dog_texts, dog_labels = mydata(dog)\n",
    "\n",
    "# Split human data to test search performance\n",
    "test_texts = human_texts[-20:]\n",
    "actual_labels = human_labels[-20:]\n",
    "human_texts = human_texts[:-20]\n",
    "human_labels = human_labels[:-20]\n",
    "\n",
    "train_texts = human_texts + chimp_texts + dog_texts\n",
    "train_labels = human_labels + chimp_labels + dog_labels\n",
    "\n",
    "print(\"train row count:\", len(train_texts))\n",
    "print(\"human({})\".format(str(len(human_texts)))\n",
    "      +\" chimp({})\".format(str(len(chimp_texts)))\n",
    "      +\" dog({})\".format(str(len(dog_texts))))\n",
    "print(\"test row count:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3c37d",
   "metadata": {},
   "source": [
    "#### 2. Generate Embeddings\n",
    "\n",
    "Extract features for DNA sequences (after k-mers) by `CountVectorizer` with previously declared dimension. Normalize output by `sklearn.preprocessing` to get final embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75165f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Transform sequences in kmers to vectors\n",
    "def char_to_vec(v_model, text):\n",
    "    V = v_model.transform(text).toarray()\n",
    "    #features = vectorizer.get_feature_names()\n",
    "    embeddings = preprocessing.normalize(V)\n",
    "    return embeddings\n",
    "\n",
    "# Train vectorizer model \n",
    "vectorizer = CountVectorizer(ngram_range=(4,4), max_features=dim)\n",
    "X = vectorizer.fit_transform(train_texts).toarray()\n",
    "train_emb = list(preprocessing.normalize(X))\n",
    "# print(vectorizer.get_feature_names())\n",
    "\n",
    "human_emb = train_emb[:len(human_texts)]\n",
    "chimp_emb = train_emb[len(human_texts):(len(human_texts)+len(chimp_texts))]\n",
    "dog_emb = train_emb[(len(human_texts)+len(chimp_texts)):len(train_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62bc40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNA_collection.num_entities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846ba6c",
   "metadata": {},
   "source": [
    "#### 3. Insert data\n",
    "\n",
    "##### Insert to Milvus\n",
    "\n",
    "Insert all embeddings to corresponding partitions with proper primary keys. Don't insert if there exists previous data in collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c223ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert collection failed.\n"
     ]
    }
   ],
   "source": [
    "human_pk = [x for x in range(len(human_emb))]\n",
    "chimp_pk = [x for x in range(len(human_emb), len(human_emb)+len(chimp_emb))]\n",
    "dog_pk = [x for x in range(len(human_emb)+len(chimp_emb), len(train_emb))]\n",
    "\n",
    "if DNA_collection.num_entities == 0:\n",
    "    DNA_human = DNA_collection.upsert([human_pk, human_emb], partition_name='human')\n",
    "    DNA_chimp = DNA_collection.upsert([chimp_pk, chimp_emb], partition_name='chimp')\n",
    "    DNA_dog = DNA_collection.upsert([dog_pk, dog_emb], partition_name='dog')\n",
    "\n",
    "    DNA_collection.compact()\n",
    "\n",
    "    if DNA_collection.is_empty:\n",
    "        print(\"Insert collection failed.\")\n",
    "    else:\n",
    "        print(DNA_collection.partitions)\n",
    "else:\n",
    "    print(\"Previous data in this collection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0585e",
   "metadata": {},
   "source": [
    "##### Insert to Mysql\n",
    "\n",
    "Insert primary keys in Milvus and corresponding labels into Mysql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e62f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MYSQL loads data to table: dna_seq successfully\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# Combine pk and label into a list\n",
    "def format_data(pk, label):\n",
    "    data = []\n",
    "    for i in range(len(pk)):\n",
    "        value = (str(pk[i]), label[i])\n",
    "        data.append(value)\n",
    "    return data\n",
    "\n",
    "def load_data_to_mysql(cursor, conn, table_name, data):\n",
    "    sql = \"insert into \" + table_name + \" (pk,label) values (%s,%s);\"\n",
    "    try:\n",
    "        cursor.executemany(sql, data)\n",
    "        conn.commit()\n",
    "        print(\"MYSQL loads data to table: {} successfully\".format(table_name))\n",
    "    except Exception as e:\n",
    "        print(\"MYSQL ERROR: {} with sql: {}\".format(e, sql))\n",
    "\n",
    "all_pk = human_pk + chimp_pk + dog_pk\n",
    "load_data_to_mysql(cursor, conn, collection_name, format_data(all_pk, train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1cea5",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Load collection. Set search parameters with Inner Product as metric_type and nprobe of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086c7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA_collection.load()\n",
    "search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 20}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d460f2",
   "metadata": {},
   "source": [
    "#### 1. Classify DNA Sequences\n",
    "\n",
    "The aim is to classify 20 human DNA sequences with labels. Inputs are pre-processed subsequences in text by k-mers (k=4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95512ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGT TGTC GTCT TCTG CTGG TGGG GGGG GGGT GGTG G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATGG TGGA GGAT GATG ATGA TGAA GAAG AAGA AGAA G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCCG CCGA CGAG GAGT AGTA GTAT TATG ATGA TGAA G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGG TGGC GGCC GCCC CCCA CCAG CAGC AGCC GCCC C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNTG NTGA TGAC GACA ACAG CAGC AGCA GCAG CAGT A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  ATGT TGTC GTCT TCTG CTGG TGGG GGGG GGGT GGTG G...\n",
       "1  ATGG TGGA GGAT GATG ATGA TGAA GAAG AAGA AGAA G...\n",
       "2  GCCG CCGA CGAG GAGT AGTA GTAT TATG ATGA TGAA G...\n",
       "3  ATGG TGGC GGCC GCCC CCCA CCAG CAGC AGCC GCCC C...\n",
       "4  NNTG NTGA TGAC GACA ACAG CAGC AGCA GCAG CAGT A..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_texts).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91054c48",
   "metadata": {},
   "source": [
    "Transform each input to vector with pre-trained vectorizer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "307498e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(text, vectorizer):\n",
    "    x = vectorizer.transform(text).toarray()\n",
    "    return list(preprocessing.normalize(x))\n",
    "\n",
    "embs = get_vector(test_texts, vectorizer)\n",
    "test_emb = []\n",
    "for x in embs:\n",
    "    test_emb.append(list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4493df",
   "metadata": {},
   "source": [
    "Search for top 10 results in human partition for each input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a57e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search...\n",
      "search latency = 0.0303s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(f\"\\nSearch...\")\n",
    "# define output_fields of search result\n",
    "res = DNA_collection.search(test_emb, \"embedding\", search_params,\n",
    "                                    limit=10, partition_names=['human'])\n",
    "end_time = time.time()\n",
    "print(\"search latency = %.4fs\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e9773",
   "metadata": {},
   "source": [
    "Display search result (recall labels from mysql by result ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4adce68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search for 'human: 1'\n",
      "[label] distance\n",
      "['human: 1'] 0.945189893245697\n",
      "['human: 1'] 0.7419408559799194\n",
      "['human: 1'] 0.6537204384803772\n",
      "['human: 1'] 0.5547619462013245\n",
      "['human: 1'] 0.5493528246879578\n",
      "['human: 5'] 0.3440358638763428\n",
      "['human: 3'] 0.3370736539363861\n",
      "['human: 5'] 0.3344237208366394\n",
      "['human: 5'] 0.3343826234340668\n",
      "['human: 5'] 0.33320432901382446\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.8693015575408936\n",
      "['human: 6'] 0.6708203554153442\n",
      "['human: 6'] 0.6575959324836731\n",
      "['human: 6'] 0.6575959324836731\n",
      "['human: 6'] 0.6060915589332581\n",
      "['human: 6'] 0.3899328112602234\n",
      "['human: 6'] 0.38864800333976746\n",
      "['human: 6'] 0.3793213963508606\n",
      "['human: 6'] 0.3793213963508606\n",
      "['human: 6'] 0.37490278482437134\n",
      "\n",
      "Search for 'human: 0'\n",
      "[label] distance\n",
      "['human: 0'] 0.5613366365432739\n",
      "['human: 0'] 0.3904344141483307\n",
      "['human: 0'] 0.35606062412261963\n",
      "['human: 0'] 0.3553272485733032\n",
      "['human: 0'] 0.34720638394355774\n",
      "['human: 0'] 0.3389814794063568\n",
      "['human: 0'] 0.25186988711357117\n",
      "['human: 4'] 0.23851391673088074\n",
      "['human: 1'] 0.2314550280570984\n",
      "['human: 1'] 0.22322094440460205\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.47358253598213196\n",
      "['human: 1'] 0.4196256995201111\n",
      "['human: 0'] 0.4168627858161926\n",
      "['human: 1'] 0.4161405563354492\n",
      "['human: 1'] 0.41306936740875244\n",
      "['human: 5'] 0.4119553864002228\n",
      "['human: 6'] 0.4114772081375122\n",
      "['human: 5'] 0.41139352321624756\n",
      "['human: 6'] 0.411154568195343\n",
      "['human: 6'] 0.41060537099838257\n",
      "\n",
      "Search for 'human: 3'\n",
      "[label] distance\n",
      "['human: 3'] 0.5423356294631958\n",
      "['human: 2'] 0.3215038478374481\n",
      "['human: 2'] 0.3213880956172943\n",
      "['human: 0'] 0.3152962923049927\n",
      "['human: 2'] 0.31449025869369507\n",
      "['human: 0'] 0.3096848726272583\n",
      "['human: 0'] 0.30896681547164917\n",
      "['human: 0'] 0.30896681547164917\n",
      "['human: 2'] 0.30728158354759216\n",
      "['human: 1'] 0.30727285146713257\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.971039891242981\n",
      "['human: 6'] 0.9230862855911255\n",
      "['human: 6'] 0.7370973825454712\n",
      "['human: 6'] 0.7247611880302429\n",
      "['human: 6'] 0.671653151512146\n",
      "['human: 6'] 0.6481538414955139\n",
      "['human: 6'] 0.6468070149421692\n",
      "['human: 6'] 0.6449602246284485\n",
      "['human: 6'] 0.612259030342102\n",
      "['human: 2'] 0.503844678401947\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.998132586479187\n",
      "['human: 6'] 0.9434680938720703\n",
      "['human: 6'] 0.7085101008415222\n",
      "['human: 2'] 0.6233519315719604\n",
      "['human: 4'] 0.6175756454467773\n",
      "['human: 4'] 0.6168562173843384\n",
      "['human: 6'] 0.6142822504043579\n",
      "['human: 2'] 0.6110934019088745\n",
      "['human: 1'] 0.6065263748168945\n",
      "['human: 1'] 0.6059770584106445\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.9999998807907104\n",
      "['human: 6'] 0.982477068901062\n",
      "['human: 6'] 0.982477068901062\n",
      "['human: 6'] 0.9671158790588379\n",
      "['human: 6'] 0.9671158790588379\n",
      "['human: 6'] 0.9541475176811218\n",
      "['human: 6'] 0.9534428715705872\n",
      "['human: 6'] 0.9457667469978333\n",
      "['human: 6'] 0.9457667469978333\n",
      "['human: 6'] 0.9422163963317871\n",
      "\n",
      "Search for 'human: 1'\n",
      "[label] distance\n",
      "['human: 1'] 0.9816546440124512\n",
      "['human: 1'] 0.9711732864379883\n",
      "['human: 1'] 0.9627828598022461\n",
      "['human: 1'] 0.9558914303779602\n",
      "['human: 1'] 0.878569483757019\n",
      "['human: 4'] 0.6015186905860901\n",
      "['human: 4'] 0.5999813079833984\n",
      "['human: 1'] 0.5901176333427429\n",
      "['human: 1'] 0.5838440656661987\n",
      "['human: 6'] 0.5589132905006409\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.9582454562187195\n",
      "['human: 6'] 0.8685867786407471\n",
      "['human: 6'] 0.6882847547531128\n",
      "['human: 6'] 0.6629990339279175\n",
      "['human: 4'] 0.5650004148483276\n",
      "['human: 4'] 0.5623874664306641\n",
      "['human: 4'] 0.5584313869476318\n",
      "['human: 3'] 0.5413483381271362\n",
      "['human: 3'] 0.5399664640426636\n",
      "['human: 0'] 0.5339840650558472\n",
      "\n",
      "Search for 'human: 0'\n",
      "[label] distance\n",
      "['human: 0'] 0.523098349571228\n",
      "['human: 0'] 0.2878538966178894\n",
      "['human: 5'] 0.27538400888442993\n",
      "['human: 0'] 0.2729080617427826\n",
      "['human: 0'] 0.26553985476493835\n",
      "['human: 5'] 0.2651236355304718\n",
      "['human: 5'] 0.2646896541118622\n",
      "['human: 1'] 0.26168954372406006\n",
      "['human: 1'] 0.2587122321128845\n",
      "['human: 1'] 0.2554903030395508\n",
      "\n",
      "Search for 'human: 6'\n",
      "[label] distance\n",
      "['human: 6'] 0.4456024169921875\n",
      "['human: 6'] 0.4451247453689575\n",
      "['human: 6'] 0.34020692110061646\n",
      "['human: 6'] 0.34020692110061646\n",
      "['human: 2'] 0.3341341018676758\n",
      "['human: 6'] 0.3340267241001129\n",
      "['human: 2'] 0.3291582465171814\n",
      "['human: 2'] 0.32824400067329407\n",
      "['human: 2'] 0.32824400067329407\n",
      "['human: 6'] 0.32745251059532166\n",
      "\n",
      "Search for 'human: 4'\n",
      "[label] distance\n",
      "['human: 4'] 0.5474622249603271\n",
      "['human: 0'] 0.42241454124450684\n",
      "['human: 1'] 0.38328540325164795\n",
      "['human: 1'] 0.38286006450653076\n",
      "['human: 5'] 0.3801782727241516\n",
      "['human: 5'] 0.3801782727241516\n",
      "['human: 0'] 0.3801417052745819\n",
      "['human: 5'] 0.3785135746002197\n",
      "['human: 4'] 0.3725740313529968\n",
      "['human: 4'] 0.3706885576248169\n",
      "\n",
      "Search for 'human: 4'\n",
      "[label] distance\n",
      "['human: 4'] 0.9445355534553528\n",
      "['human: 4'] 0.855628490447998\n",
      "['human: 4'] 0.816541314125061\n",
      "['human: 4'] 0.7607809901237488\n",
      "['human: 4'] 0.7517755031585693\n",
      "['human: 4'] 0.7517755031585693\n",
      "['human: 4'] 0.7121801376342773\n",
      "['human: 4'] 0.6960957050323486\n",
      "['human: 4'] 0.6855267882347107\n",
      "['human: 4'] 0.6620847582817078\n",
      "\n",
      "Search for 'human: 4'\n",
      "[label] distance\n",
      "['human: 4'] 0.8865680694580078\n",
      "['human: 4'] 0.8108426332473755\n",
      "['human: 4'] 0.616279125213623\n",
      "['human: 5'] 0.3926377296447754\n",
      "['human: 0'] 0.3895860016345978\n",
      "['human: 0'] 0.3888499140739441\n",
      "['human: 6'] 0.374153196811676\n",
      "['human: 6'] 0.369584858417511\n",
      "['human: 0'] 0.3669373393058777\n",
      "['human: 0'] 0.36547374725341797\n",
      "\n",
      "Search for 'human: 4'\n",
      "[label] distance\n",
      "['human: 4'] 0.9750612378120422\n",
      "['human: 4'] 0.9175235033035278\n",
      "['human: 4'] 0.6930475234985352\n",
      "['human: 4'] 0.5871579647064209\n",
      "['human: 4'] 0.5808695554733276\n",
      "['human: 4'] 0.5650359392166138\n",
      "['human: 4'] 0.5510263442993164\n",
      "['human: 4'] 0.5503541231155396\n",
      "['human: 4'] 0.5319337248802185\n",
      "['human: 4'] 0.5122694969177246\n",
      "\n",
      "Search for 'human: 4'\n",
      "[label] distance\n",
      "['human: 4'] 0.5440797805786133\n",
      "['human: 4'] 0.5415983200073242\n",
      "['human: 4'] 0.5400397777557373\n",
      "['human: 4'] 0.48557358980178833\n",
      "['human: 4'] 0.3659209907054901\n",
      "['human: 6'] 0.35602444410324097\n",
      "['human: 4'] 0.34034478664398193\n",
      "['human: 4'] 0.33678144216537476\n",
      "['human: 2'] 0.33442598581314087\n",
      "['human: 6'] 0.3323414921760559\n",
      "\n",
      "Search for 'human: 2'\n",
      "[label] distance\n",
      "['human: 2'] 0.89552241563797\n",
      "['human: 2'] 0.7853749990463257\n",
      "['human: 2'] 0.6931484937667847\n",
      "['human: 2'] 0.6931484937667847\n",
      "['human: 2'] 0.6623263359069824\n",
      "['human: 2'] 0.6229443550109863\n",
      "['human: 2'] 0.3665083348751068\n",
      "['human: 5'] 0.3442957103252411\n",
      "['human: 6'] 0.34290722012519836\n",
      "['human: 5'] 0.33900266885757446\n",
      "\n",
      "Search for 'human: 3'\n",
      "[label] distance\n",
      "['human: 3'] 0.9157936573028564\n",
      "['human: 4'] 0.471248984336853\n",
      "['human: 4'] 0.4710955023765564\n",
      "['human: 3'] 0.4439648389816284\n",
      "['human: 3'] 0.4430806040763855\n",
      "['human: 2'] 0.43611574172973633\n",
      "['human: 2'] 0.43413108587265015\n",
      "['human: 4'] 0.43208369612693787\n",
      "['human: 5'] 0.42432844638824463\n",
      "['human: 3'] 0.4203476905822754\n",
      "\n",
      "Search for 'human: 0'\n",
      "[label] distance\n",
      "['human: 0'] 0.9887166619300842\n",
      "['human: 0'] 0.9821707606315613\n",
      "['human: 0'] 0.7581608295440674\n",
      "['human: 0'] 0.7054876089096069\n",
      "['human: 0'] 0.6828335523605347\n",
      "['human: 0'] 0.5099132061004639\n",
      "['human: 0'] 0.5082061290740967\n",
      "['human: 5'] 0.5026570558547974\n",
      "['human: 4'] 0.490562379360199\n",
      "['human: 4'] 0.4890534281730652\n"
     ]
    }
   ],
   "source": [
    "def get_label_by_pk(cursor, m_pk, table_name):\n",
    "    sql = \"select label from \" + table_name + \" where pk=\" + str(m_pk) +\";\"\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        myresult = cursor.fetchall()\n",
    "        myresult = [x[0] for x in myresult]\n",
    "        return myresult\n",
    "    except Exception as e:\n",
    "        print(\"MYSQL ERROR: {} with sql: {}\".format(e, sql))\n",
    "        \n",
    "for i in range(len(res)):\n",
    "    print(\"\\nSearch for '{}'\".format(actual_labels[i]))\n",
    "    print('[label]', 'distance')\n",
    "    for x in res[i]:\n",
    "        C = get_label_by_pk(cursor, str(x.id), collection_name)\n",
    "        D = x.distance\n",
    "        print(C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036bafe",
   "metadata": {},
   "source": [
    "#### 2. Compare Similarity\n",
    "\n",
    "According to IP distance value got from similarity search in Milvus, we can compare similarities between organisms.\n",
    "\n",
    "Search top 1 results for 800 chimp/dog vectors in human partition. Average distances to reflect how close between chimp/dog and human DNA sequences. The larger the IP distance, the closer between organisims with respect to DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654eed93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chimp-human similarity score: 0.9690240950509906\n",
      "dog-human similarity score: 0.7042803590744734\n"
     ]
    }
   ],
   "source": [
    "chimp_search = []\n",
    "dog_search = []\n",
    "for x in chimp_emb[:800]:\n",
    "    chimp_search.append(list(x))\n",
    "for x in dog_emb[:800]:\n",
    "    dog_search.append(list(x))\n",
    "\n",
    "chimp_res = DNA_collection.search(chimp_search, \"embedding\", search_params,\n",
    "                                    limit=1, partition_names=['human'])\n",
    "dog_res = DNA_collection.search(dog_search, \"embedding\", search_params,\n",
    "                                    limit=1, partition_names=['human'])\n",
    "\n",
    "def similarity(search_res):\n",
    "    total_d = 0\n",
    "    for hits in search_res:\n",
    "        total_d = total_d + sum(hits.distances)/len(hits)\n",
    "    return total_d/(len(search_res))\n",
    "\n",
    "print('chimp-human similarity score:', similarity(chimp_res))\n",
    "print('dog-human similarity score:', similarity(dog_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018703e",
   "metadata": {},
   "source": [
    "From above similarity scores from milvus, we can tell that chimpanzee is closer to human compared to dog, fitting the [biological research facts](https://education.seattlepi.com/animals-share-human-dna-sequences-6693.html) \"...humans share 98.8 percent of their DNA with bonobos and chimpanzees...Humans and dogs share 84 percent of their DNA\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
